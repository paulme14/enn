{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f44a7aee",
   "metadata": {},
   "source": [
    "# Welcome to Machine Learning with Python!\n",
    "\n",
    "Hey there! ðŸ‘‹ Ready to dive into the exciting world of machine learning? This notebook will take you on a journey through the essential Python tools that every data scientist needs to know. Don't worry if you're feeling a bit overwhelmed by all the mathematical notation you see in ML papers â€“ we'll break everything down step by step!\n",
    "\n",
    "Think of this as your practical guide to understanding how data flows through machine learning pipelines. We'll work with real datasets, create beautiful visualizations, and yes, we'll even tackle some of that intimidating math â€“ but in a way that actually makes sense.\n",
    "\n",
    "## What You'll Learn (and Why It's Awesome!)\n",
    "\n",
    "### 1. **Working with Real Data**\n",
    "You know how Netflix recommends movies or how your phone recognizes faces in photos? It all starts with understanding data! We'll learn:\n",
    "- How to load and explore datasets (like the famous Iris flowers!)\n",
    "- Statistical analysis that reveals hidden patterns\n",
    "- Data preprocessing tricks that can make or break your ML models\n",
    "\n",
    "### 2. **The Language of Data**\n",
    "Ever wondered how computers \"see\" images or process spreadsheets? We'll discover:\n",
    "- **Tabular data**: Think Excel spreadsheets, but with superpowers! We represent them as feature matrices $\\mathbf{X}$ where each row is a sample and each column is a feature\n",
    "- **Image data**: Those vacation photos are actually just arrays of numbers to a computer! Images become multi-dimensional tensors $\\mathbf{I}$ with height, width, and color channels\n",
    "- **Labels**: The \"answers\" we want our AI to predict, stored in vectors $\\mathbf{y}$\n",
    "\n",
    "### 3. **Essential Data Science Skills**\n",
    "We'll master the everyday tools that data scientists use:\n",
    "- **Smart data slicing**: Grabbing exactly the data you need (like finding all cat photos in your collection)\n",
    "- **Statistical analysis**: Understanding what your data is trying to tell you\n",
    "- **Data preprocessing**: Cleaning and preparing data so your ML models can work their magic\n",
    "- **Visualization**: Creating plots that tell compelling stories about your data\n",
    "\n",
    "---\n",
    "\n",
    "**Before We Start**: This notebook assumes you're comfortable with basic Python. If you need a refresher on Python syntax, NumPy arrays, or Matplotlib plotting, check out these helpful resources:\n",
    "- `python_basics.ipynb` for Python fundamentals\n",
    "- `numpy.ipynb` for NumPy array operations  \n",
    "- `matplotlib.ipynb` for creating stunning visualizations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f7df2b",
   "metadata": {},
   "source": [
    "## Let's Get Our Tools Ready!\n",
    "\n",
    "Time to import our data science toolkits! These are the essential libraries that every ML practitioner keeps in their back pocket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab70bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris, fetch_openml\n",
    "\n",
    "# Initialise matplotlib settings\n",
    "def setup_matplotlib():\n",
    "    \"\"\"\n",
    "    Configure matplotlib for better visualization quality.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Configures global matplotlib settings for the notebook.\n",
    "    \"\"\"\n",
    "    plt.style.use('default')\n",
    "    plt.rcParams['figure.figsize'] = (10, 6)\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.rcParams['axes.grid'] = True\n",
    "    plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "setup_matplotlib()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5382bcf",
   "metadata": {},
   "source": [
    "## 1. Working with Tabular Data - Let's Meet the Iris Dataset!\n",
    "\n",
    "Ever wondered how botanists classify different species of flowers? The Iris dataset is a classic in machine learning - it contains measurements of iris flowers and their species. It's like having a digital botanist's notebook!\n",
    "\n",
    "### Understanding How Computers See Tabular Data\n",
    "\n",
    "When we load tabular data (think spreadsheet), the computer sees it as a **feature matrix** $\\mathbf{X}$, a fancy way of organizing information:\n",
    "\n",
    "$$\\mathbf{X} = \\begin{pmatrix}\n",
    "x_{1,1} & x_{1,2} & \\cdots & x_{1,d} \\\\\n",
    "x_{2,1} & x_{2,2} & \\cdots & x_{2,d} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{n,1} & x_{n,2} & \\cdots & x_{n,d}\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Here's what this means in plain English:\n",
    "- Each **row** represents one flower we measured (a sample)\n",
    "- Each **column** represents a specific measurement like petal length (a feature)\n",
    "- $n$ = total number of flowers we measured\n",
    "- $d$ = number of different measurements we took per flower\n",
    "- $x_{i,j}$ = the $j$-th measurement of the $i$-th flower\n",
    "\n",
    "Each row $\\mathbf{x}_i = (x_{i,1}, x_{i,2}, ..., x_{i,d})$ is a flower's \"profile\" - all its measurements bundled together!\n",
    "\n",
    "### Why Everyone Loves the Iris Dataset\n",
    "\n",
    "The **Iris dataset** has been famous since 1936. Here's what makes it special:\n",
    "\n",
    "**What's in the box?**\n",
    "- **150 flowers** total (50 of each species - perfectly balanced!)\n",
    "- **4 measurements** per flower (all in centimeters):\n",
    "  1. **Sepal length**: How long the sepal is (ranges 4.3-7.9 cm)\n",
    "  2. **Sepal width**: How wide the sepal is (ranges 2.0-4.4 cm)  \n",
    "  3. **Petal length**: How long the petal is (ranges 1.0-6.9 cm)\n",
    "  4. **Petal width**: How wide the petal is (ranges 0.1-2.5 cm)\n",
    "- **3 species**: Setosa, Versicolor, and Virginica\n",
    "\n",
    "**Why is it perfect for learning?**\n",
    "- **Just right size**: Big enough to be interesting, small enough to understand completely\n",
    "- **Real-world messiness**: Some species are easy to tell apart, others not so much!\n",
    "- **Visual friendly**: You can actually plot and see the patterns\n",
    "- **Proof of Concept**: If your ML algorithm can't handle Iris, it probably can't handle anything!\n",
    "\n",
    "### Target Labels\n",
    "\n",
    "We also get the **target vector** $\\mathbf{y}$ - basically the \"answer key\" telling us which species each flower is:\n",
    "- $y_i = 0$ means \"This flower is Setosa\"\n",
    "- $y_i = 1$ means \"This flower is Versicolor\"  \n",
    "- $y_i = 2$ means \"This flower is Virginica\"\n",
    "\n",
    "This number-coding system is called **label encoding** - we turn flower names into numbers so computers can work with them more easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ebebd4",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Your Turn!</b> Time to load your first real dataset!\n",
    "\n",
    "Let's build the `load_iris_dataset()` function that will become your gateway to the fascinating world of flower classification. Here's your mission: \n",
    "\n",
    "1. **Import the dataset**: Use scikit-learn's built-in Iris dataset\n",
    "2. **Extract the Components**: Grab the feature matrix X, labels y, feature names, and species names\n",
    "3. **Explore what you found**: Print some basic info so we can see what we're working with:\n",
    "    - How big is our dataset? (samples Ã— features)\n",
    "    - What measurements did the botanists take? (feature names and their ranges)\n",
    "    - Which flower species are we dealing with? (target names and how many of each)\n",
    "4. **Return** everything neatly as a tuple so we can use it later.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee8248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hints:\n",
    "# - Use: from sklearn.datasets import load_iris\n",
    "# - The loaded dataset has attributes: .data, .target, .feature_names, .target_names\n",
    "# - Use np.unique(y, return_counts=True) to get class distribution\n",
    "# - Use np.min() and np.max() to find feature ranges\n",
    "\n",
    "def load_iris_dataset():\n",
    "    \"\"\"\n",
    "    Load the Iris dataset from scikit-learn and print basic information.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (X, y, feature_names, target_names)\n",
    "        X : numpy.ndarray of shape (150, 4)\n",
    "            Feature matrix containing sepal/petal measurements\n",
    "        y : numpy.ndarray of shape (150,)\n",
    "            Target labels (0=Setosa, 1=Versicolor, 2=Virginica)\n",
    "        feature_names : list of str\n",
    "            Names of the 4 features\n",
    "        target_names : list of str\n",
    "            Names of the 3 species classes\n",
    "\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Implement the function to load the Iris dataset.\")\n",
    "    \n",
    "    return X, y, feature_names, target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ec8434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "X, y, feature_names, target_names = load_iris_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88f1381",
   "metadata": {},
   "source": [
    "### 1.1 Getting to Know Your Data - The Art of Exploration!\n",
    "\n",
    "Now that we have our dataset loaded, it's time to play detective! **Exploratory Data Analysis (EDA)** is like getting to know a new friend - you want to understand their personality, quirks, and what makes them tick. The same goes for data.\n",
    "\n",
    "**What questions should we ask our data?**\n",
    "\n",
    "1. **Size and Shape**: \n",
    "   - How much data do we have to work with? (More samples usually = happier ML algorithms!)\n",
    "   - How many features are we juggling? (Too many can be overwhelming!)\n",
    "\n",
    "2. **What Type of Data Are We Dealing With?**\n",
    "   - Are our measurements continuous numbers (like height) or categories (like colors)?\n",
    "   - What units are we working with? (Centimeters, pixels, counts?)\n",
    "   - What's the range of each measurement?\n",
    "\n",
    "3. **Statistical Personality**:\n",
    "   - **Average values**: What's typical? $\\mu = \\frac{1}{n}\\sum_{i=1}^n x_i$\n",
    "   - **Spread**: How much do values vary? $\\sigma = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\mu)^2}$\n",
    "   - **Extremes**: What are the smallest and largest values?\n",
    "\n",
    "4. **Data Quality Check**:\n",
    "   - Any missing information? (Like incomplete survey responses)\n",
    "   - Strange outliers? (Maybe someone measured a petal in meters instead of centimeters!)\n",
    "   - Are our classes balanced? (Equal numbers of each flower type, or is one species hogging the spotlight?)\n",
    "\n",
    "5. **Feature Relationships**:\n",
    "   - Do some measurements tend to go together? (Like tall people often having longer arms)\n",
    "   - Which features might be most helpful for telling species apart?\n",
    "\n",
    "**Pro Tip**: When we compute statistics, direction matters. Computing across samples (axis=0) tells us about each feature, while computing across features (axis=1) tells us about each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbde009",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Detective Time!</b> Let's analyze our dataset like a data scientist!\n",
    "    \n",
    "Build the `analyze_dataset_structure()` function to reveal all the secrets hidden in our data:\n",
    "\n",
    "1. **Getting Started**: Extract how many samples and features we have (hint: check X.shape)\n",
    "2. **Sneak peek**: Show the first 5 flowers so we can see what the data actually looks like\n",
    "3. **Crunch the numbers** (NumPy style):\n",
    "    - Calculate average measurements for each feature (what's a \"typical\" petal length?)\n",
    "    - Find the standard deviation (how much do measurements vary?)\n",
    "    - Discover the extremes (smallest and largest values for each feature)\n",
    "4. **Count the flowers**:\n",
    "    - How many of each species do we have?\n",
    "    - What percentage of our dataset does each species represent?\n",
    "5. **Make it pretty**: Print everything with nice formatting using the actual feature and species names!\n",
    "6. **Return** a dictionary with all your findings for future use\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b4e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset_structure(X, y, feature_names, target_names):\n",
    "    \"\"\"\n",
    "    Perform comprehensive exploratory data analysis on a tabular dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy.ndarray of shape (n_samples, n_features)\n",
    "        Feature matrix\n",
    "    y : numpy.ndarray of shape (n_samples,)\n",
    "        Target labels\n",
    "    feature_names : list of str\n",
    "        Names of features\n",
    "    target_names : list of str\n",
    "        Names of target classes\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Analysis results containing:\n",
    "        - 'shape': Dataset dimensions\n",
    "        - 'statistics': Mean, std, min, max per feature\n",
    "        - 'class_distribution': Sample count per class\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    raise NotImplementedError(\"Implement the function to analyze dataset structure.\")\n",
    "\n",
    "    # Shape Information\n",
    "    n_samples, n_features =\n",
    "\n",
    "    # Feature-wise statistics\n",
    "    feature_stats = {\n",
    "        'mean': ,\n",
    "        'std': ,\n",
    "        'min': ,\n",
    "        'max': \n",
    "    }\n",
    "\n",
    "    # Dataset class distribution\n",
    "    class_distribution = \n",
    "    \n",
    "    return {\n",
    "        'shape': (n_samples, n_features),\n",
    "        'statistics': feature_stats,\n",
    "        'class_distribution': class_distribution\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the Iris dataset\n",
    "analysis_results = analyze_dataset_structure(X, y, feature_names, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55a42ec",
   "metadata": {},
   "source": [
    "## 2. Working with Images - From Pixels to Patterns!\n",
    "\n",
    "Ready to dive into the world of computer vision? Let's see how computers \"see\" images! Spoiler alert: they don't see pictures like we do - they see massive grids of numbers. But that's actually pretty amazing when you think about it!\n",
    "\n",
    "### How Computers See Images - It's All About Arrays!\n",
    "\n",
    "While tabular data is like a spreadsheet, **images are like multi-dimensional grids of numbers**. Let's break this down:\n",
    "\n",
    "**Grayscale Images** (black and white): In general a single grid of brightness values.\n",
    "$$\\mathbf{I} = \\begin{pmatrix}\n",
    "I_{1,1} & I_{1,2} & \\cdots & I_{1,W} \\\\\n",
    "I_{2,1} & I_{2,2} & \\cdots & I_{2,W} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "I_{H,1} & I_{H,2} & \\cdots & I_{H,W}\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "**Color Images**: Now we have THREE grids stacked on top of each other (like a sandwich).\n",
    "- **Red layer** + **Green layer** + **Blue layer** = Full color image.\n",
    "- $H$ = how tall the image is (height in pixels)\n",
    "- $W$ = how wide the image is (width in pixels)  \n",
    "- $C$ = number of color channels (1 for B&W, 3 for RGB color)\n",
    "- $I_{i,j,c}$ = how much of color $c$ there is at position $(i,j)$\n",
    "\n",
    "### Pixel Intensity and Color Spaces\n",
    "\n",
    "**Pixel Intensities**:\n",
    "- **8-bit images**: Integer values $I_{i,j} \\in \\{0, 1, 2, ..., 255\\}$\n",
    "  - 0 = black (no intensity)\n",
    "  - 255 = white (maximum intensity)\n",
    "- **Normalized images**: Float values $I_{i,j} \\in [0, 1]$\n",
    "  - 0.0 = black, 1.0 = white\n",
    "  - Common in deep learning (better numerical stability)\n",
    "\n",
    "**RGB Color Space**: Each pixel has three components $(R, G, B)$\n",
    "- $R$ = Red channel intensity\n",
    "- $G$ = Green channel intensity  \n",
    "- $B$ = Blue channel intensity\n",
    "- Combined they produce the perceived color\n",
    "\n",
    "---\n",
    "\n",
    "### Meet MNIST - The Handwriting Dataset\n",
    "\n",
    "**MNIST** (the name for \"handwritten digits dataset\") is like the training wheels of computer vision. If Iris is about flowers, MNIST is about recognizing handwritten numbers.\n",
    "\n",
    "**Dataset Properties**:\n",
    "- **70,000 images** total (60,000 training + 10,000 test)\n",
    "- **28Ã—28 pixels** per image ($H = W = 28$)\n",
    "- **Grayscale** ($C = 1$, single channel)\n",
    "- **10 classes**: Digits 0, 1, 2, ..., 9\n",
    "- **Pixel values**: $I_{i,j} \\in [0, 255]$ (8-bit grayscale)\n",
    "\n",
    "**How does the computer see it?**\n",
    "- Feature matrix: $\\mathbf{X} \\in \\mathbb{R}^{70000 \\times 784}$ (flattened pixels)\n",
    "- Image tensor: $\\mathbf{I} \\in \\mathbb{R}^{70000 \\times 28 \\times 28}$ (spatial structure preserved)\n",
    "- Target vector: $\\mathbf{y} \\in \\{0, 1, 2, ..., 9\\}^{70000}$\n",
    "\n",
    "**Why is everyone obsessed with MNIST?**\n",
    "- **Perfect for beginners**: Small enough to experiment with quickly\n",
    "- **Benchmark dataset**: Standard for comparing algorithm performance\n",
    "- **Real-world relevance**: Basis for OCR (Optical Character Recognition) systems\n",
    "- **Visualization**: Easy to see what the algorithm is learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b08d808",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Your Digital Handwriting Adventure!</b> Time to load some real handwritten digits!\n",
    "\n",
    "Create the `load_mnist_dataset()` function to bring those handwritten digits to life:\n",
    "\n",
    "1. **Get the dataset**: Use scikit-learn's fetch_openml with name=\"mnist_784\" and version=1\n",
    "2. **Extract the goods**: Pull out the images and their corresponding digit labels\n",
    "3. **Size control**: If max_samples is specified, take just a subset\n",
    "4. **Shape it right**: Reshape the flat pixel arrays back into proper 28Ã—28 images \n",
    "5. **Clean up labels**: Convert those labels to nice clean integers (0, 1, 2, ..., 9)\n",
    "6. **Show off your findings**: Print some stats about what you loaded:\n",
    "    - How many images and what size?\n",
    "    - What's the range of pixel values? (should be 0-255)\n",
    "    - Which digits are available?\n",
    "    - How many examples of each digit do we have?\n",
    "7. Return the processed images and labels\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dcd781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes:\n",
    "# ------\n",
    "# - Original MNIST images are 28x28 pixels, grayscale\n",
    "# - Pixel intensities range from 0 (black) to 255 (white)\n",
    "# - Dataset is balanced with ~7000 samples per digit class\n",
    "\n",
    "def load_mnist_dataset(max_samples=5000):\n",
    "    \"\"\"\n",
    "    Load the MNIST handwritten digits dataset from scikit-learn.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    max_samples : int, default=5000\n",
    "        Maximum number of samples to load (for faster processing in tutorials).\n",
    "        Set to None to load all 70,000 samples.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (images, labels)\n",
    "        images : numpy.ndarray of shape (n_samples, 28, 28)\n",
    "            Grayscale images with pixel values in [0, 255]\n",
    "        labels : numpy.ndarray of shape (n_samples,)\n",
    "            Integer labels from 0-9 representing digit classes\n",
    "\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('Implement the load_mnist_dataset function.')\n",
    "\n",
    "    print(\"Loading MNIST dataset (this may take a moment)...\")\n",
    "    \n",
    "    # Load data from OpenML\n",
    "    \n",
    "    # Convert to numpy arrays and reshape\n",
    "\n",
    "    \n",
    "    # Subsample if requested (for faster processing)\n",
    "\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\n",
    "# Load MNIST dataset (using subset for faster processing)\n",
    "images, labels = load_mnist_dataset(max_samples=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5fe47",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Your First Computer Vision Gallery</b> Time to create your image visualization toolkit!. The `visualize_sample_images()` function is your gateway to displaying handwritten digits.\n",
    "\n",
    "Your implementation should: \n",
    "\n",
    "1. **Set up the gallery**: Create a subplot grid using `plt.subplots(1, n_samples, figsize=(15, 3))`\n",
    "\n",
    "2. **Handle the special case**: When `n_samples=1`, matplotlib returns a single `Axes` object (not array), consider this.\n",
    "\n",
    "3. **Display each image** (loop through `range(n_samples)`):\n",
    "   - Show image using `imshow()` with grayscale colormap (`cmap='gray'`)\n",
    "   - Set pixel range: `vmin=0, vmax=255` for consistent brightness\n",
    "   - Add title showing the label for that image\n",
    "   - Remove axis ticks and labels\n",
    "\n",
    "4. **Add overall title** to the entire figure.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feadd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_images(images, labels, n_samples=5, title=\"Sample Images\"):\n",
    "    \"\"\"\n",
    "    Display a grid of sample images with their labels.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    images : numpy.ndarray of shape (n_images, height, width)\n",
    "        Array of grayscale images\n",
    "    labels : numpy.ndarray of shape (n_images,)\n",
    "        Corresponding labels for each image\n",
    "    n_samples : int, default=5\n",
    "        Number of images to display\n",
    "    title : str, default=\"Sample Images\"\n",
    "        Title for the plot\n",
    "    \"\"\"\n",
    "\n",
    "    raise NotImplementedError(\"Implement the function to visualize sample images.\")\n",
    "\n",
    "    # Leave as is\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48018d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "visualize_sample_images(images, labels, n_samples=5, title=\"Sample MNIST Digits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fd50a7",
   "metadata": {},
   "source": [
    "## 3. Array Indexing and Slicing: Mathematical Operations on Data\n",
    "\n",
    "**Array indexing** is not just a programming conceptâ€”it's a fundamental mathematical operation for **data selection** and **subsetting**. In machine learning, we constantly need to:\n",
    "\n",
    "- **Select subsets** of data for training/validation/testing\n",
    "- **Extract specific features** for analysis\n",
    "- **Filter data** based on conditions\n",
    "- **Crop images** to focus on regions of interest\n",
    "\n",
    "### Mathematical Notation for Data Slicing\n",
    "\n",
    "**For tabular data** $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$:\n",
    "\n",
    "**Row Selection** (Sample subset):\n",
    "- $\\mathbf{X}_{[i:j, :]}$ = rows $i$ through $j-1$, all columns\n",
    "- $\\mathbf{X}_{[I, :]}$ where $I = \\{i_1, i_2, ..., i_k\\}$ = specific rows\n",
    "\n",
    "**Column Selection** (Feature subset):\n",
    "- $\\mathbf{X}_{[:, j]}$ = all rows, column $j$ (single feature)\n",
    "- $\\mathbf{X}_{[:, J]}$ where $J = \\{j_1, j_2, ..., j_m\\}$ = feature subset\n",
    "\n",
    "**Boolean Indexing** (Conditional selection):\n",
    "- $\\mathbf{X}_{[mask, :]}$ where $mask = (y == c)$ for class $c$\n",
    "- Example: $\\mathbf{X}_{setosa} = \\{x_i : y_i = 0\\}$ (all Setosa samples)\n",
    "\n",
    "### Advanced Indexing Operations\n",
    "\n",
    "**Statistical Filtering**:\n",
    "Given feature $j$ with values $\\mathbf{x}_j = (x_{1,j}, x_{2,j}, ..., x_{n,j})$:\n",
    "\n",
    "- **Outlier removal**: $mask = (|x_{i,j} - \\mu_j| < 2\\sigma_j)$\n",
    "- **Quantile filtering**: $mask = (Q_{0.25} \\leq x_{i,j} \\leq Q_{0.75})$\n",
    "- **Threshold filtering**: $mask = (x_{i,j} > \\tau)$ for threshold $\\tau$\n",
    "\n",
    "**Multi-condition Filtering**:\n",
    "- **Logical AND**: $mask_1 \\land mask_2$ (both conditions true)\n",
    "- **Logical OR**: $mask_1 \\lor mask_2$ (either condition true)\n",
    "- **Logical NOT**: $\\neg mask$ (condition false)\n",
    "\n",
    "### Image Slicing: Spatial Data Operations\n",
    "\n",
    "**For images** $\\mathbf{I} \\in \\mathbb{R}^{H \\times W}$ or $\\mathbf{I} \\in \\mathbb{R}^{H \\times W \\times C}$:\n",
    "\n",
    "**Spatial Cropping**:\n",
    "$$\\mathbf{I}_{crop} = \\mathbf{I}_{[y_1:y_2, x_1:x_2]} \\quad \\text{or} \\quad \\mathbf{I}_{[y_1:y_2, x_1:x_2, :]}$$\n",
    "\n",
    "**Common Image Operations**:\n",
    "- **Center crop**: Extract $k \\times k$ region from image center\n",
    "- **Corner extraction**: $\\mathbf{I}_{[0:k, 0:k]}$ (top-left corner)\n",
    "- **Region of Interest (ROI)**: Extract specific spatial regions\n",
    "- **Patch extraction**: For data augmentation or sliding window analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e58b93",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Tabular Data Manipulation</b> Time to master the art of smart data slicing.\n",
    "\n",
    "Your implementation should: \n",
    "\n",
    "1. **Feature subset selection**: \n",
    "   - Pick specific features (columns): `X[:10, feature_indices]`\n",
    "   - Print selected feature names and resulting shape\n",
    "\n",
    "2. **Class-based filtering** (Boolean indexing):\n",
    "   - Create boolean mask: `y == target_class`\n",
    "   - Apply mask to filter: `X[class_mask], y[class_mask]`\n",
    "   - Count and display samples for the selected class\n",
    "\n",
    "3. **Condition-based filtering**:\n",
    "   - Create condition mask: `X[:, feature_idx] > threshold`  \n",
    "   - Filter data and analyze species distribution\n",
    "   - Show sample information meeting the condition\n",
    "\n",
    "4. **Return results dictionary** with feature_subset, class_subset, and condition_subset\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af13af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_tabular_slicing(X, y, feature_names, target_names):\n",
    "    \"\"\"\n",
    "    Demonstrate various data slicing and filtering techniques on tabular data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy.ndarray of shape (n_samples, n_features)\n",
    "        Feature matrix\n",
    "    y : numpy.ndarray of shape (n_samples,)\n",
    "        Target labels\n",
    "    feature_names : list of str\n",
    "        Names of features\n",
    "    target_names : list of str\n",
    "        Names of target classes\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing sliced data examples:\n",
    "        - 'feature_subset': Selected features for first 10 samples\n",
    "        - 'class_subset': Samples belonging to specific class\n",
    "        - 'condition_subset': Samples meeting specific condition\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    raise NotImplementedError(\"Implement the function to demonstrate tabular slicing.\")\n",
    "    \n",
    "    # Example 1: Feature subset selection\n",
    "    print(\"1. FEATURE SUBSET SELECTION\")\n",
    "\n",
    "    \n",
    "    # Example 2: Class-based filtering (Boolean indexing)\n",
    "    print(f\"\\n2. CLASS-BASED FILTERING\")\n",
    "\n",
    "\n",
    "    # Example 3: Condition-based filtering\n",
    "    print(f\"\\n3. CONDITION-BASED FILTERING\")\n",
    "    \n",
    "    return {\n",
    "        'feature_subset': X_slice,\n",
    "        'class_subset': X_class,\n",
    "        'condition_subset': X_condition\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d716fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate tabular data slicing techniques\n",
    "slicing_results = demonstrate_tabular_slicing(X, y, feature_names, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2844f6",
   "metadata": {},
   "source": [
    "### Image Data Indexing: Spatial Coordinates and Array Operations\n",
    "\n",
    "**Coordinate Systems in Images**:\n",
    "\n",
    "In NumPy arrays (and most computer vision libraries), images use **matrix indexing**:\n",
    "- **First dimension**: rows (y-coordinate, vertical position)\n",
    "- **Second dimension**: columns (x-coordinate, horizontal position)\n",
    "- **Origin (0,0)**: Top-left corner of the image\n",
    "\n",
    "$$\\mathbf{I}[y, x] = \\text{pixel at row } y, \\text{ column } x$$\n",
    "\n",
    "**Spatial Relationships**:\n",
    "- Moving **right**: increase $x$ (column index)\n",
    "- Moving **down**: increase $y$ (row index)\n",
    "- **Width**: number of columns ($W$)\n",
    "- **Height**: number of rows ($H$)\n",
    "\n",
    "**Mathematical Operations on Image Regions**:\n",
    "\n",
    "**Cropping Window**: Extract subregion $\\mathbf{I}_{crop} \\in \\mathbb{R}^{h \\times w}$\n",
    "$$\\mathbf{I}_{crop} = \\mathbf{I}_{[y_{start}:y_{end}, x_{start}:x_{end}]}$$\n",
    "\n",
    "where:\n",
    "- $h = y_{end} - y_{start}$ (crop height)\n",
    "- $w = x_{end} - x_{start}$ (crop width)\n",
    "\n",
    "**Center Cropping** (common preprocessing technique):\n",
    "For image $\\mathbf{I} \\in \\mathbb{R}^{H \\times W}$, extract center region of size $h \\times w$:\n",
    "\n",
    "$$y_{start} = \\frac{H - h}{2}, \\quad x_{start} = \\frac{W - w}{2}$$\n",
    "$$y_{end} = y_{start} + h, \\quad x_{end} = x_{start} + w$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0ba2fc",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Image Cropping Basics</b>  Ever wondered how Instagram creates those perfect square crops? Or how computer vision models focus on the most important parts of an image? Image slicing!\n",
    "\n",
    "Your implementation of the `demonstrate_image_slicing` should: \n",
    "\n",
    "1. **Center cropping** (extract 14Ã—14 center region from 28Ã—28 images):\n",
    "   - Calculate start indices: `(28-14)//2 = 7` for both dimensions\n",
    "   - Extract center crop: `images[i, 7:21, 7:21]`\n",
    "   - Store in results dictionary\n",
    "\n",
    "2. **Create before/after visualization**: Show original vs cropped side-by-side\n",
    "\n",
    "3. **Return results dictionary** with all extracted regions\n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc6bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_image_slicing(images, labels, n_samples=5):\n",
    "    \"\"\"\n",
    "    Demonstrate various image slicing and cropping techniques.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    images : numpy.ndarray of shape (n_images, height, width)\n",
    "        Array of grayscale images\n",
    "    labels : numpy.ndarray of shape (n_images,)\n",
    "        Corresponding labels for each image\n",
    "    n_samples : int, default=5\n",
    "        Number of images to process and display\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing:\n",
    "        - 'original_shapes': Shape of original images\n",
    "        - 'cropped_images': List of center-cropped images\n",
    "        - 'cropped_shapes': Shape of cropped images\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    print(\"IMAGE SLICING AND CROPPING DEMONSTRATIONS\")\n",
    "    \n",
    "    raise NotImplementedError(\"Implement the function to demonstrate image slicing.\")\n",
    "\n",
    "    \n",
    "    # Calculate center crop coordinates\n",
    "\n",
    "    \n",
    "    # Perform center cropping\n",
    "\n",
    "    \n",
    "    # Visualize original vs cropped images\n",
    "\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print shape information\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'original_shapes': ,\n",
    "        'cropped_images': ,\n",
    "        'cropped_shapes': ,\n",
    "        'crop_coordinates':\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfac8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate image slicing techniques\n",
    "print(\"Applying image slicing to MNIST digits...\")\n",
    "cropping_results = demonstrate_image_slicing(images, labels, n_samples=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ac7e5",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Advanced Image Dissection!</b> You'll dissect a single digit into 8 different regions to understand how different parts contribute to recognition. This is exactly how object detection algorithms analyze images.\n",
    "\n",
    "Your implementation should: \n",
    "    \n",
    "1. **Define slicing operations dictionary** with 8 regions:\n",
    "   - 4 corner quadrants (top-left, top-right, bottom-left, bottom-right)\n",
    "   - 4 half regions (top half, bottom half, left half, right half)\n",
    "   - Use `slice(start, end)` objects for each dimension\n",
    "\n",
    "2. **Create visual dissection**:\n",
    "   - Apply each slice to the first image\n",
    "   - Create 2Ã—4 subplot grid: `plt.subplots(2, 4, figsize=(16, 8))`\n",
    "   - Display each region with title showing name and shape\n",
    "   - Use consistent grayscale scaling: `vmin=0, vmax=255`\n",
    "\n",
    "3. **Professional formatting**:\n",
    "   - Set subplot titles with region name and dimensions\n",
    "   - Remove axes for clean visualization\n",
    "   - Add overall title showing the digit label\n",
    "\n",
    "4. **Return results dictionary** with all sliced regions\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e16dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_advanced_slicing(images, labels, n_samples=3):\n",
    "    \"\"\"\n",
    "    Demonstrate advanced image slicing techniques.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    images : numpy.ndarray of shape (n_images, height, width)\n",
    "        Array of grayscale images  \n",
    "    labels : numpy.ndarray of shape (n_images,)\n",
    "        Corresponding labels\n",
    "    n_samples : int, default=3\n",
    "        Number of images to process\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Various sliced regions (corners, edges, etc.)\n",
    "    \"\"\"\n",
    "    print(f\"\\nADVANCED SLICING TECHNIQUES\")\n",
    "\n",
    "    raise NotImplementedError(\"Implement the function to demonstrate image slicing.\")\n",
    "\n",
    "    slicing_ops = {}\n",
    "\n",
    "    # Plot the Results\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {name: img[y_slice, x_slice] for name, (y_slice, x_slice) in slicing_ops.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5709c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate advanced image slicing techniques\n",
    "advanced_slicing_results = demonstrate_advanced_slicing(images, labels, n_samples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82140363",
   "metadata": {},
   "source": [
    "## 4. Data Visualization: Statistical Analysis and Pattern Recognition\n",
    "\n",
    "**Data visualization** is not just about making pretty plotsâ€”it's a crucial **analytical tool** for:\n",
    "\n",
    "1. **Understanding data distributions**: Are features normally distributed? Skewed? Multimodal?\n",
    "2. **Detecting outliers**: Values that might indicate errors or rare cases\n",
    "3. **Revealing relationships**: Correlations, clusters, and patterns\n",
    "4. **Assessing class separability**: Can classes be distinguished visually?\n",
    "5. **Validating assumptions**: Do the data meet algorithm requirements?\n",
    "6. **Debugging models**: Understanding where algorithms succeed or fail\n",
    "\n",
    "### Statistical Distributions and Their Interpretation\n",
    "\n",
    "To investigate the above stated phenomenons, data scientist have various tools to reveal information about the dataset.\n",
    "\n",
    "**Histogram Analysis**: \n",
    "\n",
    "For feature $\\mathbf{x}_j = (x_{1,j}, x_{2,j}, ..., x_{n,j})$\n",
    "\n",
    "A **histogram** shows the **empirical probability distribution**:\n",
    "- **Bins**: Intervals $[b_k, b_{k+1})$ that partition the data range\n",
    "- **Frequency**: $f_k = |\\{x_i : b_k \\leq x_i < b_{k+1}\\}|$\n",
    "- **Density**: $p_k = \\frac{f_k}{n \\cdot \\Delta b}$ where $\\Delta b$ is bin width\n",
    "\n",
    "**Common Distribution Patterns**:\n",
    "- **Normal (Gaussian)**: Bell-shaped, symmetric around mean\n",
    "  $$p(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$\n",
    "- **Skewed**: Asymmetric with long tail (positive/negative skew)\n",
    "- **Uniform**: Approximately constant across range\n",
    "- **Bimodal**: Two distinct peaks (might indicate mixed populations)\n",
    "- **Heavy-tailed**: More extreme values than normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d028abd",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Statistical Inspection</b> The secret lies in understanding feature distributions! You're about to become a data detective who can spot patterns, outliers, and hidden insights at a glance.\n",
    "\n",
    "Your implementation should: \n",
    "\n",
    "1. **Set up subplot grid**:\n",
    "   - Calculate grid dimensions and create figure with subplots\n",
    "   - Handle different grid shapes (single feature, single row, multiple rows)\n",
    "\n",
    "2. **Calculate statistics for each feature**:\n",
    "   - Extract feature data and compute mean, std, min, max using NumPy\n",
    "   - Calculate skewness \n",
    "   - store results in statistics dictionary\n",
    "\n",
    "3. **Create informative histograms**:\n",
    "   - Plot histogram with 20 bins, skyblue color and black edges\n",
    "   - Add vertical lines for mean (red dashed) and Â±1 std (orange dotted)\n",
    "   - Set title showing statistics (mean, std, skewness)\n",
    "   - Add axis labels, grid, and legend\n",
    "\n",
    "4. **Print statistical summary** with interpretation for all features\n",
    "\n",
    "5. **Return statistics dictionary** with means, stds, ranges, and skewness\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c73aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hints:\n",
    "# - Î¼â±¼ = (1/n) Î£áµ¢ xáµ¢â±¼  (mean)\n",
    "# - Ïƒâ±¼ = âˆš[(1/(n-1)) Î£áµ¢ (xáµ¢â±¼ - Î¼â±¼)Â²]  (standard deviation)\n",
    "# - Skewness = E[(X-Î¼)Â³]/ÏƒÂ³  (distribution asymmetry measure)\n",
    "\n",
    "def plot_feature_distributions(X, feature_names, title=\"Feature Distributions\"):\n",
    "    \"\"\"\n",
    "    Create histogram plots for all features to visualize their distributions and print statistical summaries.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy.ndarray of shape (n_samples, n_features)\n",
    "        Feature matrix\n",
    "    feature_names : list of str\n",
    "        Names of the features\n",
    "    title : str, default=\"Feature Distributions\"\n",
    "        Overall title for the plot\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Statistical information about each feature:\n",
    "        - 'means': Mean values per feature\n",
    "        - 'stds': Standard deviations per feature  \n",
    "        - 'skewness': Skewness values per feature\n",
    "        - 'ranges': Min-max ranges per feature\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    raise NotImplementedError(\"Implement the function to plot feature distributions.\")\n",
    "\n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    \n",
    "    # Statistical analysis results\n",
    "    stats = {\n",
    "        'means': [],\n",
    "        'stds': [],\n",
    "        'ranges': [],\n",
    "        'skewness': []\n",
    "    }\n",
    "    \n",
    "    for idx in range(n_features):\n",
    "        \n",
    "        # Extract feature data\n",
    "        \n",
    "        # Calculate statistics\n",
    "\n",
    "        # Store statistics\n",
    "        stats['means'].append(mean_val)\n",
    "        stats['stds'].append(std_val)\n",
    "        stats['ranges'].append((min_val, max_val))\n",
    "        stats['skewness'].append(skewness)\n",
    "        \n",
    "        # Create histogram\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    \n",
    "    # Plot the Results\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistical summary   \n",
    "    for i, name in enumerate(feature_names):\n",
    "\n",
    "    \n",
    "    return stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce35f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions for the Iris dataset\n",
    "distribution_stats = plot_feature_distributions(X, feature_names, \n",
    "                                               title=\"Iris Dataset: Feature Distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0277a1",
   "metadata": {},
   "source": [
    "### Scatter Plots: Exploring Feature Relationships and Class Separability\n",
    "\n",
    "A **scatter plot** visualizes the joint distribution of two features $(x_i, x_j)$:\n",
    "- **X-axis**: Feature $i$ values\n",
    "- **Y-axis**: Feature $j$ values  \n",
    "- **Each point**: One data sample $(x_{k,i}, x_{k,j})$\n",
    "\n",
    "Its a powefull tool to get a first impression of the data and provide guidance for further analysis. When points are colored by class, scatter plots reveal:\n",
    "\n",
    "- **Linear separability**: Classes can be separated by a straight line\n",
    "- **Cluster structure**: Distinct groups in feature space\n",
    "- **Overlap regions**: Where classification will be difficult\n",
    "- **Decision boundaries**: Where optimal separation might occur\n",
    "\n",
    "**Correlation Analysis**:\n",
    "\n",
    "\n",
    "The **Pearson correlation coefficient** measures linear relationship strength:\n",
    "$$r_{ij} = \\frac{\\sum_{k=1}^n (x_{k,i} - \\mu_i)(x_{k,j} - \\mu_j)}{\\sqrt{\\sum_{k=1}^n (x_{k,i} - \\mu_i)^2 \\sum_{k=1}^n (x_{k,j} - \\mu_j)^2}}$$\n",
    "\n",
    "**Interpretation**:\n",
    "\n",
    "- $r_{ij} = +1$: Perfect positive linear correlation\n",
    "- $r_{ij} = 0$: No linear correlation (but nonlinear relationships may exist)\n",
    "- $r_{ij} = -1$: Perfect negative linear correlation\n",
    "\n",
    "**Correlation Strength**\n",
    "\n",
    "- $|r_{ij}| > 0.7$: Strong correlation\n",
    "- $|r_{ij}| < 0.3$: Weak correlation\n",
    "\n",
    "Correlation analysis helps identify redundant features, where two variables carry similar information. Highly correlated features may lead to multicollinearity, which can negatively affect some models (e.g., linear regression). On the other hand, identifying uncorrelated or weakly correlated features can uncover complementary information, making them valuable for classification or prediction. However, correlation only captures linear relationshipsâ€”nonlinear patterns may still exist even when $r_{ij} = 0$, so it's essential to combine correlation analysis with visual tools like scatter plots for a complete understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18d589a",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Dataset Relationship</b> Time to uncover the hidden connections in your data. You're about to create scatter plots that reveal which features work together and which classes can be easily separated.\n",
    "\n",
    "Your implementation of the `plot_feature_relationships` should: \n",
    "\n",
    "1. **Set up feature pairs and grid layout**:\n",
    "   - Calculate grid dimensions and create subplot grid with appropriate figure size\n",
    "\n",
    "2. **Compute correlation matrix**:\n",
    "   - Use `np.corrcoef(X.T)` to calculate Pearson correlation coefficients\n",
    "   - This reveals linear relationships between all feature pairs\n",
    "\n",
    "3. **Create informative scatter plots**:\n",
    "   - Extract feature data and plot points for each class with different colors\n",
    "   - Use `scatter()` with `alpha=0.7, edgecolors='black', s=60`\n",
    "   - Calculate and mark class centroids with 'X' markers\n",
    "\n",
    "4. **Professional formatting**:\n",
    "   - Set axis labels and titles with correlation values\n",
    "   - Add grid, legend, and proper formatting\n",
    "   - Hide unused subplots for clean appearance\n",
    "\n",
    "5. **Print correlation analysis**:\n",
    "   - Display correlation score\n",
    "\n",
    "6. **Return results dictionary** with correlation_matrix\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3233ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_relationships(X, y, feature_names, target_names, \n",
    "                               feature_pairs=None, figsize=(15, 10)):\n",
    "    \"\"\"\n",
    "    Create scatter plots to visualize relationships between feature pairs.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy.ndarray of shape (n_samples, n_features)\n",
    "        Feature matrix\n",
    "    y : numpy.ndarray of shape (n_samples,)\n",
    "        Target labels\n",
    "    feature_names : list of str\n",
    "        Names of features\n",
    "    target_names : list of str\n",
    "        Names of target classes\n",
    "    feature_pairs : list of tuples, optional\n",
    "        Specific feature pairs to plot. If None, plots all combinations.\n",
    "    figsize : tuple, default=(15, 10)\n",
    "        Figure size for the plot\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Correlation analysis results:\n",
    "        - 'correlation_matrix': Pearson correlation coefficients\n",
    "        - 'separability_scores': Class separability measures per feature pair\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    raise NotImplementedError(\"Implement the function to plot feature relationships.\")\n",
    "\n",
    "    # Define feature pairs to plot\n",
    "    if feature_pairs is None:\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    \n",
    "    # Craft the Scatter Plots\n",
    "    \n",
    "    # Hide empty subplots\n",
    "\n",
    "    # Plot the Results\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print analysis results\n",
    "    return {\n",
    "        'correlation_matrix': correlation_matrix,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81502f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature relationships in the Iris dataset\n",
    "relationship_analysis = plot_feature_relationships(X, y, feature_names, target_names,\n",
    "                                                  feature_pairs=[(2, 3), (0, 2), (1, 3)],\n",
    "                                                  figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d667f",
   "metadata": {},
   "source": [
    "### Image Data Visualization: Understanding Visual Patterns\n",
    "\n",
    "For datasets like MNIST, each digit class has characteristic patterns:\n",
    "- **Digit 0**: Circular structure, hollow center\n",
    "- **Digit 1**: Vertical lines, minimal width\n",
    "- **Digit 8**: Two loops, complex topology\n",
    "- **Within-class variation**: Different handwriting styles\n",
    "- **Between-class similarity**: Digits 6 and 9 are similar when rotated\n",
    "\n",
    "Visualizing image data helps uncover both statistical properties and structural patterns relevant for classification or preprocessing.\n",
    "\n",
    "**Pixel Intensity Analysis**:\n",
    "For grayscale image $\\mathbf{I} \\in \\mathbb{R}^{H \\times W}$, we can analyze:\n",
    "\n",
    "**Global Statistics**:\n",
    "\n",
    "- **Mean intensity**: $\\mu_I = \\frac{1}{HW} \\sum_{i=1}^H \\sum_{j=1}^W I_{i,j}$\n",
    "- **Standard deviation**: $\\sigma_I = \\sqrt{\\frac{1}{HW-1} \\sum_{i=1}^H \\sum_{j=1}^W (I_{i,j} - \\mu_I)^2}$\n",
    "- **Dynamic range**: $[I_{min}, I_{max}]$ where $I_{min} = \\min_{i,j} I_{i,j}$, $I_{max} = \\max_{i,j} I_{i,j}$\n",
    "\n",
    "These metrics give a first-order summary of brightness, contrast, and range in the image data.\n",
    "\n",
    "**Histogram Analysis for Images**:\n",
    "\n",
    "The **pixel intensity histogram** shows the distribution of brightness values. This analysis is useful for preprocessing steps like normalization, contrast adjustment, or thresholding.\n",
    "\n",
    "- **Dark images**: Histogram concentrated at low values (0-100)\n",
    "- **Bright images**: Histogram concentrated at high values (150-255)\n",
    "- **High contrast**: Histogram spread across full range\n",
    "- **Low contrast**: Histogram concentrated in narrow range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7e351d",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "\n",
    "<b>Digital Gallery</b> Time to create a handwritten digit showcase. .\n",
    "\n",
    "Build your `visualize_digit_examples()` function to:\n",
    "\n",
    "1. **Discover your collection**: Find all unique digits and set up the perfect gallery layout\n",
    "    - Use np.unique(labels) to find all digit classes present\n",
    "    - Calculate grid dimensions\n",
    "    - Create subplot grid with appropriate figure size\n",
    "2. **Select representative examples**: Find the first specimen of each digit and count your entire collection  \n",
    "3. **Create professional displays**: Show each digit with beautiful formatting and clean visualization\n",
    "    - For each digit, find first occurrence using np.where(labels == digit)[0]\n",
    "    - Store example index and count total samples per class\n",
    "    - Display image using imshow() with grayscale colormap and proper scaling\n",
    "    - Set title showing digit value and sample count\n",
    "4. **Handle the unexpected**: Gracefully manage missing digits and empty spaces\n",
    "    - If no samples exist for a digit, display \"No samples\" message\n",
    "    - Hide unused subplots for clean appearance\n",
    "    - Remove axis ticks for cleaner visualization\n",
    "5. **Provide collection insights**: Print detailed statistics about your digital artifact distribution\n",
    "    - Show sample count and percentage for each digit class\n",
    "    - Format output clearly with proper alignment   \n",
    "6. **Return analysis results** a dictionary with example_indices and class_counts\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946a2fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_digit_examples(images, labels, title=\"Digit Examples\"):\n",
    "    \"\"\"\n",
    "    Display one example of each digit class (0-9) from the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    images : numpy.ndarray of shape (n_samples, height, width)\n",
    "        Array of digit images\n",
    "    labels : numpy.ndarray of shape (n_samples,)\n",
    "        Corresponding digit labels (0-9)\n",
    "    title : str, default=\"Digit Examples\"\n",
    "        Title for the visualization\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Information about the examples:\n",
    "        - 'example_indices': Index of the example used for each digit\n",
    "        - 'class_counts': Number of samples per digit class\n",
    "    \n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Implement the function to visualize digit examples.\") \n",
    "\n",
    "    unique_digits = np.unique(labels)\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "\n",
    "    # Craft the Subplots and extract statistics    \n",
    "    for i, digit in enumerate(unique_digits):\n",
    "\n",
    "    # Plot the Results\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print class distribution\n",
    "    for digit in sorted(class_counts.keys()):\n",
    "    \n",
    "    return {\n",
    "        'example_indices': example_indices,\n",
    "        'class_counts': class_counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519cd703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize examples of each digit class\n",
    "digit_examples = visualize_digit_examples(images, labels, \n",
    "                                         title=\"MNIST Dataset: One Example per Digit Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a7725",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "\n",
    "<b>Pixel Intensity Inspection</b> Ever wondered how photo editing apps analyze brightness and contrast? You're about to build the same analysis tools that photographers use to perfect their images!\n",
    "\n",
    "Create the `analyze_pixel_intensity_distribution()` function to:\n",
    "\n",
    "1. **Set up analysis parameters**:\n",
    "    - Handle sample_indices parameter\n",
    "    - Calculate grid layout for visualization\n",
    "    - Create subplot grid with extra column for combined histogram\n",
    "2. **Statistical analysis per image**: \n",
    "    - Calculate statistical measures: mean, std, min, max using NumPy\n",
    "    - Store results in analysis_results dictionary\n",
    "    - Generate histogram data: np.histogram(pixels, bins=50, range=(0, 255))\n",
    "3. **Create professional visualizations**: \n",
    "    - Display original images with statistical info in titles\n",
    "    - Create individual histograms showing pixel intensity distributions\n",
    "    - Combine all histograms in final subplot with different colors\n",
    "    - Use proper labels, legends, and formatting\n",
    "4. **Print detailed summary**: Show intensity ranges and dynamic range for each sample\n",
    "5. **Return comprehensive results**: Dictionary with all statistical measures and histogram data\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93786e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pixel_intensity_distribution(images, sample_indices=None, title=\"Pixel Intensity Analysis\"):\n",
    "    \"\"\"\n",
    "    Analyze and visualize pixel intensity distributions in images.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    images : numpy.ndarray of shape (n_samples, height, width)\n",
    "        Array of images\n",
    "    sample_indices : list or None, default=None\n",
    "        Specific image indices to analyze. If None, analyzes first image.\n",
    "    title : str, default=\"Pixel Intensity Analysis\"\n",
    "        Title for the visualization\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Statistical analysis results:\n",
    "        - 'mean_intensities': Mean pixel intensity per image\n",
    "        - 'std_intensities': Standard deviation per image\n",
    "        - 'intensity_ranges': Min-max ranges per image\n",
    "        - 'histogram_data': Histogram data for visualization\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    raise NotImplementedError(\"Implement the function to analyze pixel intensity distribution.\")\n",
    "    \n",
    "    analysis_results = {\n",
    "        'mean_intensities': [],\n",
    "        'std_intensities': [],\n",
    "        'intensity_ranges': [],\n",
    "        'histogram_data': []\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Calculate grid for subplots\n",
    "\n",
    "\n",
    "    # Calculate statistics and plot images\n",
    "    for idx, sample_idx in enumerate(sample_indices):       \n",
    "        # Extract image and flatten for analysis\n",
    "        \n",
    "        # Statistical analysis\n",
    "        \n",
    "        # Display original image\n",
    "\n",
    "        # Create histogram\n",
    "    \n",
    "    # Combined histogram plot\n",
    "\n",
    "    # Plot the Results\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistical summary\n",
    "    \n",
    "    return analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4444e486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze pixel intensity distributions for sample images\n",
    "intensity_analysis = analyze_pixel_intensity_distribution(images, \n",
    "                                                        sample_indices=[0, 100, 500], \n",
    "                                                        title=\"Pixel Intensity Distribution Analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ais-nn)",
   "language": "python",
   "name": "ais-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
