{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Run Online](https://jupyterhub.uni-muenster.de/hub/user-redirect/git-pull?repo=https%3A%2F%2Fzivgitlab.uni-muenster.de%2Fai-systems%2Fteaching%2Fpublic%2Fws-25%2Feinfuehrung-neuronale-netze&urlpath=lab%2Ftree%2Feinfuehrung-neuronale-netze%2F01+Python+Intro%2Fintro_python.ipynb&branch=main)\n",
        "\n",
        "## Online Python tutorials\n",
        "\n",
        "* [core functionality required for the course](https://colab.research.google.com/github/mbp-lab/Neural-Networks-HCAI/blob/master/Intro%20Colab%2BTensors.ipynb)\n",
        "* Python Basics: [en](https://docs.python.org/3/tutorial) / [de](https://py-tutorial-de.readthedocs.io/de/python-3.3)\n",
        "* [python+colab tutorial](https://colab.research.google.com/github/cs231n/cs231n.github.io/blob/master/python-colab.ipynb)\n",
        "* [matplotlib tutorials](https://matplotlib.org/stable/tutorials/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Display random walk data\n",
        "\n",
        "A random walk adds a (small) random vector to the current state $x(t)$ like this: $x(t+1) = x(t) + \\eta$, where $\\eta$ is just a random variable, e.g. uniformly distributed in range $[-1, 1]$.\n",
        "\n",
        "1. Generate a 1d random walk time series, starting from $x(0) = 0$ and display the series with matplotlib (as $x(t)$).\n",
        "2. Generate a 2d random walk time series, starting from $x(0) = 0$ and display the series with matplotlib (as $x_2(x_1)$).\n",
        "\n",
        "Avoid using any manual loops (`for` or `while`), but use numpy array functions instead. For example, look for [`cumsum`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.cumsum.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "eta = np.random.uniform(-1.0, 1.0, size=(100,))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. More Plotting\n",
        "\n",
        "1. Display the two-dimensional manifold $z=x \\cdot y$ as a [wireframe and surface plot](https://matplotlib.org/stable/tutorials/toolkits/mplot3d.html#toolkit-mplot3d-tutorial).\n",
        "Sample the data in the range $[-1,1]^2$ with 20 samples in each direction.\n",
        "\n",
        "2. Randomly select 30 images from the MNIST dataset and display them in a $5 \\times 6$ grid using subplots.\n",
        "\n",
        "Again, avoid explicit loops as far as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Tensors\n",
        "\n",
        "1. Split the MNIST data set into 120 batches รก 500 samples and arrange them as a 4d tensor with the shape (120, 500, 28, 28).\n",
        "\n",
        "2. Create a new shuffling of these batches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Broadcast Operations\n",
        "In order to perform polynomial fitting we will need to collect the powers $x^1, x^2, x^3, x^4$ of our data samples x in a design matrix A with\n",
        "\n",
        "$A_{ij} = x_i^j$\n",
        " \n",
        "Create this matrix employing numpy's vectorization and broadcasting capabilities. Don't write an explicit loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.arange(-1,1,0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Timing\n",
        "\n",
        "Use [timeit](https://docs.python.org/3.8/library/timeit.html) to compare the computation time required for `naive_add` introduced [here](https://colab.research.google.com/github/mbp-lab/Neural-Networks-HCAI/blob/master/Intro%20Colab%2BTensors.ipynb) and numpy's vector-based *add*. For meaningful results, consider random matrices of size larger than $1000^2$."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Assignment 1, Neural Network Basics",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
