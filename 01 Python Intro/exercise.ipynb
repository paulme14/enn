{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f44a7aee",
   "metadata": {},
   "source": [
    "# Welcome to Machine Learning with Python!\n",
    "\n",
    "Hey there! ðŸ‘‹ Ready to dive into the exciting world of machine learning? This notebook will take you on a journey through the essential Python tools that every data scientist needs to know. Don't worry if you're feeling a bit overwhelmed by all the mathematical notation you see in ML papers â€“ we'll break everything down step by step!\n",
    "\n",
    "Think of this as your practical guide to understanding how data flows through machine learning pipelines. We'll work with real datasets, create beautiful visualizations, and yes, we'll even tackle some of that intimidating math â€“ but in a way that actually makes sense.\n",
    "\n",
    "## What You'll Learn (and Why It's Awesome!)\n",
    "\n",
    "### 1. **Working with Real Data**\n",
    "You know how Netflix recommends movies or how your phone recognizes faces in photos? It all starts with understanding data! We'll learn:\n",
    "- How to load and explore datasets (like the famous Iris flowers!)\n",
    "- Statistical analysis that reveals hidden patterns\n",
    "- Data preprocessing tricks that can make or break your ML models\n",
    "\n",
    "### 2. **The Language of Data**\n",
    "Ever wondered how computers \"see\" images or process spreadsheets? We'll discover:\n",
    "- **Tabular data**: Think Excel spreadsheets, but with superpowers! We represent them as feature matrices $\\mathbf{X}$ where each row is a sample and each column is a feature\n",
    "- **Image data**: Those vacation photos are actually just arrays of numbers to a computer! Images become multi-dimensional tensors $\\mathbf{I}$ with height, width, and color channels\n",
    "- **Labels**: The \"answers\" we want our AI to predict, stored in vectors $\\mathbf{y}$\n",
    "\n",
    "### 3. **Essential Data Science Skills**\n",
    "We'll master the everyday tools that data scientists use:\n",
    "- **Smart data slicing**: Grabbing exactly the data you need (like finding all cat photos in your collection)\n",
    "- **Visualization**: Creating plots that tell compelling stories about your data\n",
    "\n",
    "---\n",
    "\n",
    "**Before We Start**: This notebook assumes you're comfortable with basic Python. If you need a refresher on Python syntax, NumPy arrays, or Matplotlib plotting, check out these helpful resources:\n",
    "- `python_basics.ipynb` for Python fundamentals\n",
    "- `numpy.ipynb` for NumPy array operations  \n",
    "- `matplotlib.ipynb` for creating stunning visualizations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f7df2b",
   "metadata": {},
   "source": [
    "## Let's Get Our Tools Ready!\n",
    "\n",
    "Time to import our data science toolkits! These are the essential libraries that every ML practitioner keeps in their back pocket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab70bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris, fetch_openml\n",
    "\n",
    "# Initialise matplotlib settings\n",
    "def setup_matplotlib():\n",
    "    \"\"\"\n",
    "    Configure matplotlib for better visualization quality.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Configures global matplotlib settings for the notebook.\n",
    "    \"\"\"\n",
    "    plt.style.use('default')\n",
    "    plt.rcParams['figure.figsize'] = (10, 6)\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.rcParams['axes.grid'] = True\n",
    "    plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "setup_matplotlib()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5382bcf",
   "metadata": {},
   "source": [
    "## 1. Working with Tabular Data - Let's Meet the Iris Dataset!\n",
    "\n",
    "Ever wondered how botanists classify different species of flowers? The Iris dataset is a classic in machine learning - it contains measurements of iris flowers and their species. It's like having a digital botanist's notebook!\n",
    "\n",
    "### Understanding How Computers See Tabular Data\n",
    "\n",
    "When we load tabular data (think spreadsheet), the computer sees it as a **feature matrix** $\\mathbf{X}$, a fancy way of organizing information:\n",
    "\n",
    "$$\\mathbf{X} = \\begin{pmatrix}\n",
    "x_{1,1} & x_{1,2} & \\cdots & x_{1,d} \\\\\n",
    "x_{2,1} & x_{2,2} & \\cdots & x_{2,d} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{n,1} & x_{n,2} & \\cdots & x_{n,d}\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Here's what this means in plain English:\n",
    "- Each **row** represents one flower we measured (a sample)\n",
    "- Each **column** represents a specific measurement like petal length (a feature)\n",
    "- $n$ = total number of flowers we measured\n",
    "- $d$ = number of different measurements we took per flower\n",
    "- $x_{i,j}$ = the $j$-th measurement of the $i$-th flower\n",
    "\n",
    "Each row $\\mathbf{x}_i = (x_{i,1}, x_{i,2}, ..., x_{i,d})$ is a flower's \"profile\" - all its measurements bundled together!\n",
    "\n",
    "### Why Everyone Loves the Iris Dataset\n",
    "\n",
    "The **Iris dataset** has been famous since 1936. Here's what makes it special:\n",
    "\n",
    "**What's in the box?**\n",
    "- **150 flowers** total (50 of each species - perfectly balanced!)\n",
    "- **4 measurements** per flower (all in centimeters):\n",
    "  1. **Sepal length**: How long the sepal is (ranges 4.3-7.9 cm)\n",
    "  2. **Sepal width**: How wide the sepal is (ranges 2.0-4.4 cm)  \n",
    "  3. **Petal length**: How long the petal is (ranges 1.0-6.9 cm)\n",
    "  4. **Petal width**: How wide the petal is (ranges 0.1-2.5 cm)\n",
    "- **3 species**: Setosa, Versicolor, and Virginica\n",
    "\n",
    "**Why is it perfect for learning?**\n",
    "- **Just right size**: Big enough to be interesting, small enough to understand completely\n",
    "- **Real-world messiness**: Some species are easy to tell apart, others not so much!\n",
    "- **Visual friendly**: You can actually plot and see the patterns\n",
    "- **Proof of Concept**: If your ML algorithm can't handle Iris, it probably can't handle anything!\n",
    "\n",
    "### Target Labels\n",
    "\n",
    "We also get the **target vector** $\\mathbf{y}$ - basically the \"answer key\" telling us which species each flower is:\n",
    "- $y_i = 0$ means \"This flower is Setosa\"\n",
    "- $y_i = 1$ means \"This flower is Versicolor\"  \n",
    "- $y_i = 2$ means \"This flower is Virginica\"\n",
    "\n",
    "This number-coding system is called **label encoding** - we turn flower names into numbers so computers can work with them more easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ebebd4",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Your Turn!</b> Time to load your first real dataset!\n",
    "\n",
    "Let's build the `load_iris_dataset()` function that will become your gateway to the fascinating world of flower classification. Here's your mission: \n",
    "\n",
    "1. **Import the dataset**: Use scikit-learn's built-in Iris dataset\n",
    "2. **Extract the Components**: Grab the feature matrix X, labels y, feature names, and species names\n",
    "3. **Explore what you found**: Print some basic info so we can see what we're working with:\n",
    "    - How big is our dataset? (samples Ã— features)\n",
    "    - What measurements did the botanists take? (feature names and their ranges)\n",
    "    - Which flower species are we dealing with? (target names and how many of each)\n",
    "4. **Return** everything neatly as a tuple so we can use it later.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee8248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hints:\n",
    "# - Use: from sklearn.datasets import load_iris\n",
    "# - The loaded dataset has attributes: .data, .target, .feature_names, .target_names\n",
    "# - Use np.unique(y, return_counts=True) to get class distribution\n",
    "# - Use np.min() and np.max() to find feature ranges\n",
    "\n",
    "def load_iris_dataset():\n",
    "    \"\"\"\n",
    "    Load the Iris dataset from scikit-learn and print basic information.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (X, y, feature_names, target_names)\n",
    "        X : numpy.ndarray of shape (150, 4)\n",
    "            Feature matrix containing sepal/petal measurements\n",
    "        y : numpy.ndarray of shape (150,)\n",
    "            Target labels (0=Setosa, 1=Versicolor, 2=Virginica)\n",
    "        feature_names : list of str\n",
    "            Names of the 4 features\n",
    "        target_names : list of str\n",
    "            Names of the 3 species classes\n",
    "\n",
    "    \"\"\"\n",
    "    # Load using sklearn's helper\n",
    "    data = load_iris()\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    feature_names = list(data.feature_names)\n",
    "    target_names = list(data.target_names)\n",
    "\n",
    "    # Print helpful diagnostics requested by the notebook\n",
    "    print(\"Iris dataset loaded.\")\n",
    "    print(f\"Shape: {X.shape} (samples x features)\")\n",
    "    for i, name in enumerate(feature_names):\n",
    "        col = X[:, i]\n",
    "        print(f\" - {name}: min={col.min():.2f}, max={col.max():.2f}, mean={col.mean():.2f}, std={col.std():.2f}\")\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    class_info = {target_names[u]: int(c) for u, c in zip(unique, counts)}\n",
    "    print(\"Class distribution:\", class_info)\n",
    "\n",
    "    return X, y, feature_names, target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ec8434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris dataset loaded.\n",
      "Shape: (150, 4) (samples x features)\n",
      " - sepal length (cm): min=4.30, max=7.90, mean=5.84, std=0.83\n",
      " - sepal width (cm): min=2.00, max=4.40, mean=3.06, std=0.43\n",
      " - petal length (cm): min=1.00, max=6.90, mean=3.76, std=1.76\n",
      " - petal width (cm): min=0.10, max=2.50, mean=1.20, std=0.76\n",
      "Class distribution: {np.str_('setosa'): 50, np.str_('versicolor'): 50, np.str_('virginica'): 50}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the dataset\n",
    "X, y, feature_names, target_names = load_iris_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88f1381",
   "metadata": {},
   "source": [
    "### 1.1 Getting to Know Your Data - The Art of Exploration!\n",
    "\n",
    "Now that we have our dataset loaded, it's time to play detective! **Exploratory Data Analysis (EDA)** is like getting to know a new friend - you want to understand their personality, quirks, and what makes them tick. The same goes for data.\n",
    "\n",
    "**What questions should we ask our data?**\n",
    "\n",
    "1. **Size and Shape**: \n",
    "   - How much data do we have to work with? (More samples usually = happier ML algorithms!)\n",
    "   - How many features are we juggling? (Too many can be overwhelming!)\n",
    "\n",
    "2. **What Type of Data Are We Dealing With?**\n",
    "   - Are our measurements continuous numbers (like height) or categories (like colors)?\n",
    "   - What units are we working with? (Centimeters, pixels, counts?)\n",
    "   - What's the range of each measurement?\n",
    "\n",
    "3. **Statistical Personality**:\n",
    "   - **Average values**: What's typical? $\\mu = \\frac{1}{n}\\sum_{i=1}^n x_i$\n",
    "   - **Spread**: How much do values vary? $\\sigma = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\mu)^2}$\n",
    "   - **Extremes**: What are the smallest and largest values?\n",
    "\n",
    "4. **Data Quality Check**:\n",
    "   - Any missing information? (Like incomplete survey responses)\n",
    "   - Strange outliers? (Maybe someone measured a petal in meters instead of centimeters!)\n",
    "   - Are our classes balanced? (Equal numbers of each flower type, or is one species hogging the spotlight?)\n",
    "\n",
    "5. **Feature Relationships**:\n",
    "   - Do some measurements tend to go together? (Like tall people often having longer arms)\n",
    "   - Which features might be most helpful for telling species apart?\n",
    "\n",
    "**Pro Tip**: When we compute statistics, direction matters. Computing across samples (axis=0) tells us about each feature, while computing across features (axis=1) tells us about each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbde009",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Detective Time!</b> Let's analyze our dataset like a data scientist!\n",
    "    \n",
    "Build the `analyze_dataset_structure()` function to reveal all the secrets hidden in our data:\n",
    "\n",
    "1. **Getting Started**: Extract how many samples and features we have (hint: check X.shape)\n",
    "2. **Sneak peek**: Show the first 5 flowers so we can see what the data actually looks like\n",
    "3. **Crunch the numbers** (NumPy style):\n",
    "    - Calculate average measurements for each feature (what's a \"typical\" petal length?)\n",
    "    - Find the standard deviation (how much do measurements vary?)\n",
    "    - Discover the extremes (smallest and largest values for each feature)\n",
    "4. **Count the flowers**:\n",
    "    - How many of each species do we have?\n",
    "    - What percentage of our dataset does each species represent?\n",
    "5. **Make it pretty**: Print everything with nice formatting using the actual feature and species names!\n",
    "6. **Return** a dictionary with all your findings for future use\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e6b4e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset_structure(X, y, feature_names, target_names):\n",
    "    \"\"\"\n",
    "    Perform comprehensive exploratory data analysis on a tabular dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy.ndarray of shape (n_samples, n_features)\n",
    "        Feature matrix\n",
    "    y : numpy.ndarray of shape (n_samples,)\n",
    "        Target labels\n",
    "    feature_names : list of str\n",
    "        Names of features\n",
    "    target_names : list of str\n",
    "        Names of target classes\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Analysis results containing:\n",
    "        - 'shape': Dataset dimensions\n",
    "        - 'statistics': Mean, std, min, max per feature\n",
    "        - 'class_distribution': Sample count per class\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Basic shape info\n",
    "    n_samples, n_features = X.shape\n",
    "    print(f\"Dataset shape: {n_samples} samples, {n_features} features\")\n",
    "\n",
    "    # Sneak peek: first 5 samples\n",
    "    print(\"First 5 samples (rows):\")\n",
    "    print(X[:5])\n",
    "\n",
    "    # Feature-wise statistics (compute along axis=0)\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    minv = np.min(X, axis=0)\n",
    "    maxv = np.max(X, axis=0)\n",
    "\n",
    "    feature_stats = {\n",
    "        'mean': mean.tolist(),\n",
    "        'std': std.tolist(),\n",
    "        'min': minv.tolist(),\n",
    "        'max': maxv.tolist()\n",
    "    }\n",
    "\n",
    "    # Dataset class distribution (counts and percentages)\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    class_counts = {target_names[int(u)]: int(c) for u, c in zip(unique, counts)}\n",
    "    class_percent = {target_names[int(u)]: float(c) / n_samples * 100.0 for u, c in zip(unique, counts)}\n",
    "    class_distribution = {'counts': class_counts, 'percent': class_percent}\n",
    "\n",
    "    # Pretty print statistics using provided names\n",
    "    print(\"Feature statistics:\")\n",
    "    for i, name in enumerate(feature_names):\n",
    "        print(f\" - {name}: mean={mean[i]:.2f}, std={std[i]:.2f}, min={minv[i]:.2f}, max={maxv[i]:.2f}\")\n",
    "    print(\"Class distribution (counts):\", class_counts)\n",
    "    print(\"Class distribution (%):\", {k: f\"{v:.1f}%\" for k, v in class_percent.items()})\n",
    "\n",
    "    return {\n",
    "        'shape': (n_samples, n_features),\n",
    "        'statistics': feature_stats,\n",
    "        'class_distribution': class_distribution\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3500668d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: 150 samples, 4 features\n",
      "First 5 samples (rows):\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "Feature statistics:\n",
      " - sepal length (cm): mean=5.84, std=0.83, min=4.30, max=7.90\n",
      " - sepal width (cm): mean=3.06, std=0.43, min=2.00, max=4.40\n",
      " - petal length (cm): mean=3.76, std=1.76, min=1.00, max=6.90\n",
      " - petal width (cm): mean=1.20, std=0.76, min=0.10, max=2.50\n",
      "Class distribution (counts): {np.str_('setosa'): 50, np.str_('versicolor'): 50, np.str_('virginica'): 50}\n",
      "Class distribution (%): {np.str_('setosa'): '33.3%', np.str_('versicolor'): '33.3%', np.str_('virginica'): '33.3%'}\n"
     ]
    }
   ],
   "source": [
    "# Analyze the Iris dataset\n",
    "analysis_results = analyze_dataset_structure(X, y, feature_names, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55a42ec",
   "metadata": {},
   "source": [
    "## 2. Working with Images - From Pixels to Patterns!\n",
    "\n",
    "Ready to dive into the world of computer vision? Let's see how computers \"see\" images! Spoiler alert: they don't see pictures like we do - they see massive grids of numbers. But that's actually pretty amazing when you think about it!\n",
    "\n",
    "### How Computers See Images - It's All About Arrays!\n",
    "\n",
    "While tabular data is like a spreadsheet, **images are like multi-dimensional grids of numbers**. Let's break this down:\n",
    "\n",
    "**Grayscale Images** (black and white): In general a single grid of brightness values.\n",
    "$$\\mathbf{I} = \\begin{pmatrix}\n",
    "I_{1,1} & I_{1,2} & \\cdots & I_{1,W} \\\\\n",
    "I_{2,1} & I_{2,2} & \\cdots & I_{2,W} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "I_{H,1} & I_{H,2} & \\cdots & I_{H,W}\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "**Color Images**: Now we have THREE grids stacked on top of each other (like a sandwich).\n",
    "- **Red layer** + **Green layer** + **Blue layer** = Full color image.\n",
    "- $H$ = how tall the image is (height in pixels)\n",
    "- $W$ = how wide the image is (width in pixels)  \n",
    "- $C$ = number of color channels (1 for B&W, 3 for RGB color)\n",
    "- $I_{i,j,c}$ = how much of color $c$ there is at position $(i,j)$\n",
    "\n",
    "### Pixel Intensity and Color Spaces\n",
    "\n",
    "**Pixel Intensities**:\n",
    "- **8-bit images**: Integer values $I_{i,j} \\in \\{0, 1, 2, ..., 255\\}$\n",
    "  - 0 = black (no intensity)\n",
    "  - 255 = white (maximum intensity)\n",
    "- **Normalized images**: Float values $I_{i,j} \\in [0, 1]$\n",
    "  - 0.0 = black, 1.0 = white\n",
    "  - Common in deep learning (better numerical stability)\n",
    "\n",
    "**RGB Color Space**: Each pixel has three components $(R, G, B)$\n",
    "- $R$ = Red channel intensity\n",
    "- $G$ = Green channel intensity  \n",
    "- $B$ = Blue channel intensity\n",
    "- Combined they produce the perceived color\n",
    "\n",
    "---\n",
    "\n",
    "### Meet MNIST - The Handwriting Dataset\n",
    "\n",
    "**MNIST** (the name for \"handwritten digits dataset\") is like the training wheels of computer vision. If Iris is about flowers, MNIST is about recognizing handwritten numbers.\n",
    "\n",
    "**Dataset Properties**:\n",
    "- **70,000 images** total (60,000 training + 10,000 test)\n",
    "- **28Ã—28 pixels** per image ($H = W = 28$)\n",
    "- **Grayscale** ($C = 1$, single channel)\n",
    "- **10 classes**: Digits 0, 1, 2, ..., 9\n",
    "- **Pixel values**: $I_{i,j} \\in [0, 255]$ (8-bit grayscale)\n",
    "\n",
    "**How does the computer see it?**\n",
    "- Feature matrix: $\\mathbf{X} \\in \\mathbb{R}^{70000 \\times 784}$ (flattened pixels)\n",
    "- Image tensor: $\\mathbf{I} \\in \\mathbb{R}^{70000 \\times 28 \\times 28}$ (spatial structure preserved)\n",
    "- Target vector: $\\mathbf{y} \\in \\{0, 1, 2, ..., 9\\}^{70000}$\n",
    "\n",
    "**Why is everyone obsessed with MNIST?**\n",
    "- **Perfect for beginners**: Small enough to experiment with quickly\n",
    "- **Benchmark dataset**: Standard for comparing algorithm performance\n",
    "- **Real-world relevance**: Basis for OCR (Optical Character Recognition) systems\n",
    "- **Visualization**: Easy to see what the algorithm is learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b08d808",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Your Digital Handwriting Adventure!</b> Time to load some real handwritten digits!\n",
    "\n",
    "Create the `load_mnist_dataset()` function to bring those handwritten digits to life:\n",
    "\n",
    "1. **Get the dataset**: Use scikit-learn's fetch_openml with name=\"mnist_784\" and version=1\n",
    "2. **Extract the goods**: Pull out the images and their corresponding digit labels\n",
    "3. **Size control**: If max_samples is specified, take just a subset\n",
    "4. **Shape it right**: Reshape the flat pixel arrays back into proper 28Ã—28 images \n",
    "5. **Clean up labels**: Convert those labels to nice clean integers (0, 1, 2, ..., 9)\n",
    "6. **Show off your findings**: Print some stats about what you loaded:\n",
    "    - How many images and what size?\n",
    "    - What's the range of pixel values? (should be 0-255)\n",
    "    - Which digits are available?\n",
    "    - How many examples of each digit do we have?\n",
    "7. Return the processed images and labels\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dcd781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes:\n",
    "# ------\n",
    "# - Original MNIST images are 28x28 pixels, grayscale\n",
    "# - Pixel intensities range from 0 (black) to 255 (white)\n",
    "# - Dataset is balanced with ~7000 samples per digit class\n",
    "\n",
    "def load_mnist_dataset(max_samples=5000):\n",
    "    \"\"\"\n",
    "    Load the MNIST handwritten digits dataset from scikit-learn.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    max_samples : int, default=5000\n",
    "        Maximum number of samples to load (for faster processing in tutorials).\n",
    "        Set to None to load all 70,000 samples.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (images, labels)\n",
    "        images : numpy.ndarray of shape (n_samples, 28, 28)\n",
    "            Grayscale images with pixel values in [0, 255]\n",
    "        labels : numpy.ndarray of shape (n_samples,)\n",
    "            Integer labels from 0-9 representing digit classes\n",
    "\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('Implement the load_mnist_dataset function.')\n",
    "\n",
    "    print(\"Loading MNIST dataset (this may take a moment)...\")\n",
    "    \n",
    "    # Load data from OpenML\n",
    "    \n",
    "    # Convert to numpy arrays and reshape\n",
    "\n",
    "    \n",
    "    # Subsample if requested (for faster processing)\n",
    "\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\n",
    "# Load MNIST dataset (using subset for faster processing)\n",
    "images, labels = load_mnist_dataset(max_samples=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5fe47",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Your First Computer Vision Gallery</b> Time to create your image visualization toolkit!. The `visualize_sample_images()` function is your gateway to displaying handwritten digits.\n",
    "\n",
    "Your implementation should: \n",
    "\n",
    "1. **Set up the gallery**: Create a subplot grid using `plt.subplots(1, n_samples, figsize=(15, 3))`\n",
    "\n",
    "2. **Handle the special case**: When `n_samples=1`, matplotlib returns a single `Axes` object (not array), consider this.\n",
    "\n",
    "3. **Display each image** (loop through `range(n_samples)`):\n",
    "   - Show image using `imshow()` with grayscale colormap (`cmap='gray'`)\n",
    "   - Set pixel range: `vmin=0, vmax=255` for consistent brightness\n",
    "   - Add title showing the label for that image\n",
    "   - Remove axis ticks and labels\n",
    "\n",
    "4. **Add overall title** to the entire figure.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feadd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_images(images, labels, n_samples=5, title=\"Sample Images\"):\n",
    "    \"\"\"\n",
    "    Display a grid of sample images with their labels.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    images : numpy.ndarray of shape (n_images, height, width)\n",
    "        Array of grayscale images\n",
    "    labels : numpy.ndarray of shape (n_images,)\n",
    "        Corresponding labels for each image\n",
    "    n_samples : int, default=5\n",
    "        Number of images to display\n",
    "    title : str, default=\"Sample Images\"\n",
    "        Title for the plot\n",
    "    \"\"\"\n",
    "\n",
    "    raise NotImplementedError(\"Implement the function to visualize sample images.\")\n",
    "\n",
    "    # Leave as is\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48018d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "visualize_sample_images(images, labels, n_samples=5, title=\"Sample MNIST Digits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fd50a7",
   "metadata": {},
   "source": [
    "## 3. Array Indexing and Slicing: Mathematical Operations on Data\n",
    "\n",
    "**Array indexing** is not just a programming conceptâ€”it's a fundamental mathematical operation for **data selection** and **subsetting**. In machine learning, we constantly need to:\n",
    "\n",
    "- **Select subsets** of data for training/validation/testing\n",
    "- **Extract specific features** for analysis\n",
    "- **Filter data** based on conditions\n",
    "- **Crop images** to focus on regions of interest\n",
    "\n",
    "### Mathematical Notation for Data Slicing\n",
    "\n",
    "**For tabular data** $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$:\n",
    "\n",
    "**Row Selection** (Sample subset):\n",
    "- $\\mathbf{X}_{[i:j, :]}$ = rows $i$ through $j-1$, all columns\n",
    "- $\\mathbf{X}_{[I, :]}$ where $I = \\{i_1, i_2, ..., i_k\\}$ = specific rows\n",
    "\n",
    "**Column Selection** (Feature subset):\n",
    "- $\\mathbf{X}_{[:, j]}$ = all rows, column $j$ (single feature)\n",
    "- $\\mathbf{X}_{[:, J]}$ where $J = \\{j_1, j_2, ..., j_m\\}$ = feature subset\n",
    "\n",
    "**Boolean Indexing** (Conditional selection):\n",
    "- $\\mathbf{X}_{[mask, :]}$ where $mask = (y == c)$ for class $c$\n",
    "- Example: $\\mathbf{X}_{setosa} = \\{x_i : y_i = 0\\}$ (all Setosa samples)\n",
    "\n",
    "### Advanced Indexing Operations\n",
    "\n",
    "**Statistical Filtering**:\n",
    "Given feature $j$ with values $\\mathbf{x}_j = (x_{1,j}, x_{2,j}, ..., x_{n,j})$:\n",
    "\n",
    "- **Outlier removal**: $mask = (|x_{i,j} - \\mu_j| < 2\\sigma_j)$\n",
    "- **Quantile filtering**: $mask = (Q_{0.25} \\leq x_{i,j} \\leq Q_{0.75})$\n",
    "- **Threshold filtering**: $mask = (x_{i,j} > \\tau)$ for threshold $\\tau$\n",
    "\n",
    "**Multi-condition Filtering**:\n",
    "- **Logical AND**: $mask_1 \\land mask_2$ (both conditions true)\n",
    "- **Logical OR**: $mask_1 \\lor mask_2$ (either condition true)\n",
    "- **Logical NOT**: $\\neg mask$ (condition false)\n",
    "\n",
    "### Image Slicing: Spatial Data Operations\n",
    "\n",
    "**For images** $\\mathbf{I} \\in \\mathbb{R}^{H \\times W}$ or $\\mathbf{I} \\in \\mathbb{R}^{H \\times W \\times C}$:\n",
    "\n",
    "**Spatial Cropping**:\n",
    "$$\\mathbf{I}_{crop} = \\mathbf{I}_{[y_1:y_2, x_1:x_2]} \\quad \\text{or} \\quad \\mathbf{I}_{[y_1:y_2, x_1:x_2, :]}$$\n",
    "\n",
    "**Common Image Operations**:\n",
    "- **Center crop**: Extract $k \\times k$ region from image center\n",
    "- **Corner extraction**: $\\mathbf{I}_{[0:k, 0:k]}$ (top-left corner)\n",
    "- **Region of Interest (ROI)**: Extract specific spatial regions\n",
    "- **Patch extraction**: For data augmentation or sliding window analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e58b93",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Tabular Data Manipulation</b> Time to master the art of smart data slicing.\n",
    "\n",
    "Your implementation should: \n",
    "\n",
    "1. **Feature subset selection**: \n",
    "   - Pick specific features (columns): `X[:10, feature_indices]`\n",
    "   - Print selected feature names and resulting shape\n",
    "\n",
    "2. **Class-based filtering** (Boolean indexing):\n",
    "   - Create boolean mask: `y == target_class`\n",
    "   - Apply mask to filter: `X[class_mask], y[class_mask]`\n",
    "   - Count and display samples for the selected class\n",
    "\n",
    "3. **Condition-based filtering**:\n",
    "   - Create condition mask: `X[:, feature_idx] > threshold`  \n",
    "   - Filter data and analyze species distribution\n",
    "   - Show sample information meeting the condition\n",
    "\n",
    "4. **Return results dictionary** with feature_subset, class_subset, and condition_subset\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af13af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_tabular_slicing(X, y, feature_names, target_names):\n",
    "    \"\"\"\n",
    "    Demonstrate various data slicing and filtering techniques on tabular data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy.ndarray of shape (n_samples, n_features)\n",
    "        Feature matrix\n",
    "    y : numpy.ndarray of shape (n_samples,)\n",
    "        Target labels\n",
    "    feature_names : list of str\n",
    "        Names of features\n",
    "    target_names : list of str\n",
    "        Names of target classes\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing sliced data examples:\n",
    "        - 'feature_subset': Selected features for first 10 samples\n",
    "        - 'class_subset': Samples belonging to specific class\n",
    "        - 'condition_subset': Samples meeting specific condition\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    raise NotImplementedError(\"Implement the function to demonstrate tabular slicing.\")\n",
    "    \n",
    "    # Example 1: Feature subset selection\n",
    "    print(\"1. FEATURE SUBSET SELECTION\")\n",
    "\n",
    "    \n",
    "    # Example 2: Class-based filtering (Boolean indexing)\n",
    "    print(f\"\\n2. CLASS-BASED FILTERING\")\n",
    "\n",
    "\n",
    "    # Example 3: Condition-based filtering\n",
    "    print(f\"\\n3. CONDITION-BASED FILTERING\")\n",
    "    \n",
    "    return {\n",
    "        'feature_subset': X_slice,\n",
    "        'class_subset': X_class,\n",
    "        'condition_subset': X_condition\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d716fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate tabular data slicing techniques\n",
    "slicing_results = demonstrate_tabular_slicing(X, y, feature_names, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2844f6",
   "metadata": {},
   "source": [
    "### Image Data Indexing: Spatial Coordinates and Array Operations\n",
    "\n",
    "**Coordinate Systems in Images**:\n",
    "\n",
    "In NumPy arrays (and most computer vision libraries), images use **matrix indexing**:\n",
    "- **First dimension**: rows (y-coordinate, vertical position)\n",
    "- **Second dimension**: columns (x-coordinate, horizontal position)\n",
    "- **Origin (0,0)**: Top-left corner of the image\n",
    "\n",
    "$$\\mathbf{I}[y, x] = \\text{pixel at row } y, \\text{ column } x$$\n",
    "\n",
    "**Spatial Relationships**:\n",
    "- Moving **right**: increase $x$ (column index)\n",
    "- Moving **down**: increase $y$ (row index)\n",
    "- **Width**: number of columns ($W$)\n",
    "- **Height**: number of rows ($H$)\n",
    "\n",
    "**Mathematical Operations on Image Regions**:\n",
    "\n",
    "**Cropping Window**: Extract subregion $\\mathbf{I}_{crop} \\in \\mathbb{R}^{h \\times w}$\n",
    "$$\\mathbf{I}_{crop} = \\mathbf{I}_{[y_{start}:y_{end}, x_{start}:x_{end}]}$$\n",
    "\n",
    "where:\n",
    "- $h = y_{end} - y_{start}$ (crop height)\n",
    "- $w = x_{end} - x_{start}$ (crop width)\n",
    "\n",
    "**Center Cropping** (common preprocessing technique):\n",
    "For image $\\mathbf{I} \\in \\mathbb{R}^{H \\times W}$, extract center region of size $h \\times w$:\n",
    "\n",
    "$$y_{start} = \\frac{H - h}{2}, \\quad x_{start} = \\frac{W - w}{2}$$\n",
    "$$y_{end} = y_{start} + h, \\quad x_{end} = x_{start} + w$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0ba2fc",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Image Cropping Basics</b>  Ever wondered how Instagram creates those perfect square crops? Or how computer vision models focus on the most important parts of an image? Image slicing!\n",
    "\n",
    "Your implementation of the `demonstrate_image_slicing` should: \n",
    "\n",
    "1. **Center cropping** (extract 14Ã—14 center region from 28Ã—28 images):\n",
    "   - Calculate start indices: `(28-14)//2 = 7` for both dimensions\n",
    "   - Extract center crop: `images[i, 7:21, 7:21]`\n",
    "   - Store in results dictionary\n",
    "\n",
    "2. **Create before/after visualization**: Show original vs cropped side-by-side\n",
    "\n",
    "3. **Return results dictionary** with all extracted regions\n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc6bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_image_slicing(images, labels, n_samples=5):\n",
    "    \"\"\"\n",
    "    Demonstrate various image slicing and cropping techniques.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    images : numpy.ndarray of shape (n_images, height, width)\n",
    "        Array of grayscale images\n",
    "    labels : numpy.ndarray of shape (n_images,)\n",
    "        Corresponding labels for each image\n",
    "    n_samples : int, default=5\n",
    "        Number of images to process and display\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing:\n",
    "        - 'original_shapes': Shape of original images\n",
    "        - 'cropped_images': List of center-cropped images\n",
    "        - 'cropped_shapes': Shape of cropped images\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    print(\"IMAGE SLICING AND CROPPING DEMONSTRATIONS\")\n",
    "    \n",
    "    raise NotImplementedError(\"Implement the function to demonstrate image slicing.\")\n",
    "\n",
    "    \n",
    "    # Calculate center crop coordinates\n",
    "\n",
    "    \n",
    "    # Perform center cropping\n",
    "\n",
    "    \n",
    "    # Visualize original vs cropped images\n",
    "\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print shape information\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'original_shapes': ,\n",
    "        'cropped_images': ,\n",
    "        'cropped_shapes': ,\n",
    "        'crop_coordinates':\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfac8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate image slicing techniques\n",
    "print(\"Applying image slicing to MNIST digits...\")\n",
    "cropping_results = demonstrate_image_slicing(images, labels, n_samples=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ac7e5",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <b>Advanced Image Dissection!</b> You'll dissect a single digit into 8 different regions to understand how different parts contribute to recognition. This is exactly how object detection algorithms analyze images.\n",
    "\n",
    "Your implementation should: \n",
    "    \n",
    "1. **Define slicing operations dictionary** with 8 regions:\n",
    "   - 4 corner quadrants (top-left, top-right, bottom-left, bottom-right)\n",
    "   - 4 half regions (top half, bottom half, left half, right half)\n",
    "   - Use `slice(start, end)` objects for each dimension\n",
    "\n",
    "2. **Create visual dissection**:\n",
    "   - Apply each slice to the first image\n",
    "   - Create 2Ã—4 subplot grid: `plt.subplots(2, 4, figsize=(16, 8))`\n",
    "   - Display each region with title showing name and shape\n",
    "   - Use consistent grayscale scaling: `vmin=0, vmax=255`\n",
    "\n",
    "3. **Professional formatting**:\n",
    "   - Set subplot titles with region name and dimensions\n",
    "   - Remove axes for clean visualization\n",
    "   - Add overall title showing the digit label\n",
    "\n",
    "4. **Return results dictionary** with all sliced regions\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e16dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_advanced_slicing(images, labels, n_samples=3):\n",
    "    \"\"\"\n",
    "    Demonstrate advanced image slicing techniques.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    images : numpy.ndarray of shape (n_images, height, width)\n",
    "        Array of grayscale images  \n",
    "    labels : numpy.ndarray of shape (n_images,)\n",
    "        Corresponding labels\n",
    "    n_samples : int, default=3\n",
    "        Number of images to process\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Various sliced regions (corners, edges, etc.)\n",
    "    \"\"\"\n",
    "    print(f\"\\nADVANCED SLICING TECHNIQUES\")\n",
    "\n",
    "    raise NotImplementedError(\"Implement the function to demonstrate image slicing.\")\n",
    "\n",
    "    slicing_ops = {}\n",
    "\n",
    "    # Plot the Results\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {name: img[y_slice, x_slice] for name, (y_slice, x_slice) in slicing_ops.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5709c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate advanced image slicing techniques\n",
    "advanced_slicing_results = demonstrate_advanced_slicing(images, labels, n_samples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba08c8e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Wrapping Up\n",
    "\n",
    "You have now completed a practical introduction to working with tabular and image data in Python. Throughout this notebook, you have developed essential skills for loading, analyzing, slicing, and visualizing real-world datasets â€” the core competencies for any machine learning practitioner.\n",
    "\n",
    "The next phase of your journey will focus on **Exploratory Data Analysis (EDA)**. EDA enables you to uncover patterns, relationships, and potential issues within your data before building predictive models.\n",
    "\n",
    "## Next Steps: Homework Assignment\n",
    "\n",
    "Your upcoming homework will extend the concepts and techniques introduced here. Check out the homework.ipynb where you will:\n",
    "\n",
    "- Apply advanced EDA methods to the Iris and MNIST Dataset\n",
    "- Visualize data distributions, correlations, and outliers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
